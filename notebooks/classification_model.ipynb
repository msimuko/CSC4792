{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91620dd",
   "metadata": {},
   "source": [
    "# Reference Classification Model\n",
    "\n",
    "This notebook implements a machine learning pipeline to classify academic references by publication type.\n",
    "\n",
    "**Objective**: Automatically categorize bibliographic references into types like journal articles, books, theses, etc.\n",
    "\n",
    "**Approach**: \n",
    "- Text preprocessing and cleaning\n",
    "- TF-IDF feature extraction\n",
    "- Multinomial Naive Bayes classification\n",
    "- Model evaluation and performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c653e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path for importing utils\n",
    "sys.path.append('../src')\n",
    "from utils import clean_reference\n",
    "\n",
    "# Cell 3 - Data Loading\n",
    "# Load the reference data\n",
    "try:\n",
    "    df = pd.read_csv('../data/references.csv')\n",
    "    print(f\"Data loaded successfully. Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"references.csv not found. Please ensure your data file is in the data/ directory\")\n",
    "    print(\"Expected columns: 'reference_text', 'publication_type'\")\n",
    "    # Create sample data structure for demonstration\n",
    "    df = pd.DataFrame({\n",
    "        'reference_text': ['Sample journal reference...', 'Sample book reference...'],\n",
    "        'publication_type': ['journal', 'book']\n",
    "    })\n",
    "\n",
    "# Cell 4 - Data Preprocessing\n",
    "# Clean the reference texts\n",
    "print(\"Cleaning reference texts...\")\n",
    "df['cleaned_reference'] = df['reference_text'].apply(clean_reference)\n",
    "\n",
    "# Remove any empty references after cleaning\n",
    "df = df[df['cleaned_reference'].str.len() > 0]\n",
    "\n",
    "print(f\"Data after cleaning: {df.shape}\")\n",
    "print(\"\\nPublication type distribution:\")\n",
    "print(df['publication_type'].value_counts())\n",
    "\n",
    "# Cell 5 - Train-Test Split\n",
    "# Split the data\n",
    "X = df['cleaned_reference']\n",
    "y = df['publication_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "# Cell 6 - Model Training\n",
    "# Create and train the classification pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "print(\"Training the model...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")\n",
    "\n",
    "# Cell 7 - Model Evaluation\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"=\" * 30)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Cell 8 - Feature Analysis\n",
    "# Get feature names and importance (top TF-IDF features)\n",
    "feature_names = pipeline.named_steps['tfidf'].get_feature_names_out()\n",
    "tfidf_scores = pipeline.named_steps['tfidf'].transform(X_train).mean(axis=0).A1\n",
    "\n",
    "# Get top features\n",
    "top_features_idx = tfidf_scores.argsort()[-20:][::-1]\n",
    "top_features = [(feature_names[i], tfidf_scores[i]) for i in top_features_idx]\n",
    "\n",
    "print(\"Top 20 TF-IDF Features:\")\n",
    "print(\"=\" * 40)\n",
    "for feature, score in top_features:\n",
    "    print(f\"{feature}: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
